{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# 202: Exampville Mode Choice Logsums\n",
    "\n",
    "Welcome to Exampville, the best simulated town in this here part of the internet!\n",
    "\n",
    "Exampville is a demonstration provided with Larch that walks through some of the \n",
    "data and tools that a transportation planner might use when building a travel model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "from pytest import approx\n",
    "\n",
    "import larch as lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from addicty import Dict\n",
    "\n",
    "import larch as lx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "In this example notebook, we will walk through the creation of logsums from\n",
    "an existing tour mode choice model.  First, let's load the data files from\n",
    "our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "hh, pp, tour, skims = lx.example(200, [\"hh\", \"pp\", \"tour\", \"skims\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "We'll also load the saved model from the mode choice estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "exampville_mode_choice_file = lx.example(\n",
    "    201, output_file=\"exampville_mode_choice.html\", estimate=True\n",
    ")\n",
    "m = lx.load_model(exampville_mode_choice_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "We'll replicate the pre-processing used in the mode choice estimation,\n",
    "to merge the household and person characteristics into the tours data,\n",
    "add the index values for the home TAZ's, filter to include only \n",
    "work tours, and merge with the level of service skims.  (If this \n",
    "pre-processing was computationally expensive, it would probably have\n",
    "been better to save the results to disk and reload them as needed,\n",
    "but for this model these commands will run almost instantaneously.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "Mode = Dict(\n",
    "    DA=1,\n",
    "    SR=2,\n",
    "    Walk=3,\n",
    "    Bike=4,\n",
    "    Transit=5,\n",
    ").freeze()\n",
    "\n",
    "tour_dataset = lx.Dataset.construct.from_idco(tour.set_index(\"TOURID\"), alts=Mode)\n",
    "od_skims = lx.Dataset.construct.from_omx(skims)\n",
    "\n",
    "dt = lx.DataTree(\n",
    "    tour=tour_dataset.dc.query_cases(\"TOURPURP == 1\"),\n",
    "    hh=hh.set_index(\"HHID\"),\n",
    "    person=pp.set_index(\"PERSONID\"),\n",
    "    od=od_skims,\n",
    "    do=od_skims,\n",
    "    relationships=(\n",
    "        \"tours.HHID @ hh.HHID\",\n",
    "        \"tours.PERSONID @ person.PERSONID\",\n",
    "        \"hh.HOMETAZ @ od.otaz\",\n",
    "        \"tours.DTAZ @ od.dtaz\",\n",
    "        \"hh.HOMETAZ @ do.dtaz\",\n",
    "        \"tours.DTAZ @ do.otaz\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Then we bundle the raw data into the `larch.DataFrames` structure,\n",
    "as we did for estimation, and attach this structure to the model\n",
    "as its `dataservice`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "We'll also initialize a DataArray to hold the computed logsums.\n",
    "This data will have one row for each case in our source data,\n",
    "and a column for each possible destination zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "logsums = lx.DataArray.zeros(\n",
    "    dt.caseids(),\n",
    "    skims.TAZ_ID,\n",
    "    name=\"logsums\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The logsums from a Model can be computed using the `Model.logsums` method.\n",
    "However, if we want the logsums for each possible destination, we'll need\n",
    "to replace the part of our data that depends on the destination zone, \n",
    "writing in the appropriate values for each.  We can simply iterate over the\n",
    "zones, dropping in the zone as the destination and computing the logsums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dtaz in logsums.TAZ_ID:\n",
    "    m.datatree = dt.replace_datasets(\n",
    "        tour=dt.root_dataset.assign(DTAZ=xr.full_like(dt._getitem(\"DTAZ\"), dtaz)),\n",
    "    )\n",
    "    logsums.loc[dict(TAZ_ID=dtaz)] = m.logsums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert logsums[:4, :5].values == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-3.046127, -2.770006, -1.823385, -2.320373, -2.4941],\n",
    "        ]\n",
    "    ),\n",
    "    rel=1e-3,\n",
    ")\n",
    "assert logsums.shape == (7564, 40)\n",
    "assert logsums[-4:, -5:].values == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [-0.354058, -0.729078, -1.164068, -0.421579, -0.913035],\n",
    "            [-0.354058, -0.729078, -1.164068, -0.421579, -0.913035],\n",
    "            [-0.246731, -0.721721, -1.156756, -0.354397, -0.890595],\n",
    "            [-0.391292, -0.731449, -1.166416, -0.444101, -0.920291],\n",
    "        ]\n",
    "    ),\n",
    "    rel=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Then we can persist the logsums dataframe to disk, for use in the next\n",
    "example, where we will estimate a destination choice model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.isdir(\"logsums.zarr\"):\n",
    "    shutil.rmtree(\"logsums.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "logsums.to_zarr(\"logsums.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the DataArray later, we can read it using the `DataArray.from_zarr` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx.DataArray.from_zarr(\"logsums.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "reloaded = lx.DataArray.from_zarr(\"logsums.zarr\")\n",
    "assert reloaded[:4, :5].values == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-2.935642, -2.660468, -1.745647, -2.229293, -2.403132],\n",
    "            [-3.046127, -2.770006, -1.823385, -2.320373, -2.4941],\n",
    "        ]\n",
    "    ),\n",
    "    rel=1e-3,\n",
    ")\n",
    "assert reloaded.shape == (7564, 40)\n",
    "assert reloaded[-4:, -5:].values == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [-0.354058, -0.729078, -1.164068, -0.421579, -0.913035],\n",
    "            [-0.354058, -0.729078, -1.164068, -0.421579, -0.913035],\n",
    "            [-0.246731, -0.721721, -1.156756, -0.354397, -0.890595],\n",
    "            [-0.391292, -0.731449, -1.166416, -0.444101, -0.920291],\n",
    "        ]\n",
    "    ),\n",
    "    rel=1e-3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
