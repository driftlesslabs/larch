{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Mixed Logit Estimation Exercise\n",
    "\n",
    "This problem set originates from Professor Ken Train's course on discrete choice.\n",
    "Many thanks to him for allowing us to adapt it for use with Larch. It is provided\n",
    "here with only minor modifications.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/driftlesslabs/larch/blob/main/exercises/mixed-logit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "If you run this notebook in CoLab, you'll need to install `larch` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q larch6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We will estimate mixed logit models in this problem set. The data represent \n",
    "consumers' choices among vehicles in stated preference experiments. The data are \n",
    "from a study that he did for Toyota and GM to assist them in their analysis of \n",
    "the potential marketability of electric and hybrid vehicles, back before hybrids \n",
    "were introduced to the public.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Vehicle Type Choice Data\n",
    "\n",
    "In each choice experiment, the respondent was presented with three vehicles, with \n",
    "the price and other attributes of each vehicle described. The respondent was asked \n",
    "to state which of the three vehicles he/she would buy if the these vehicles were \n",
    "the only ones available in the market. There are 100 respondents in the dataset\n",
    "for this exercise (the full dataset had 500 respondents). Each respondent was \n",
    "presented with 15 choice experiments, and most respondents answered all 15. The \n",
    "attributes of the vehicles were varied over experiments, both for a given \n",
    "respondent and over respondents. The attributes are: price, operating cost in \n",
    "dollars per month, engine type (gas, electric, or hybrid), range if electric (in \n",
    "hundreds of miles between recharging), and the performance level of the vehicle \n",
    "(high, medium, or low). The performance level was described in terms of top speed \n",
    "and acceleration, and these descriptions did not vary for each level; for example, \n",
    "\"High\" performance was described as having a top speed of 100 mph and 12 seconds \n",
    "to reach 60 mph, and this description was the same for all \"high\" performance \n",
    "vehicles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import larch as lx\n",
    "from larch import PX\n",
    "\n",
    "raw_data = pd.read_parquet(lx.example_file(\"vehicle_choice.parquet\"))\n",
    "data = lx.Dataset.construct.from_idca(raw_data)\n",
    "data[\"price_scaled\"] = data[\"price\"] / 10000\n",
    "data[\"opcost_scaled\"] = data[\"opcost\"] / 10\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## First Things First\n",
    "\n",
    "It is always best to start with a standard logit model. To save you time, the \n",
    "script to produce a simple MNL model is provided below.\n",
    "\n",
    "  - Do the estimated coefficients have the expected signs?\n",
    "  - What is the estimated willingness to pay for a $1 per month reduction in\n",
    "    operating cost? Note that price is in tens of thousands of dollars, and\n",
    "    operating cost is in tens of dollars.\n",
    "  - The variable \"medhiperf\" is 1 if the vehicle has either medium or high\n",
    "    performance and 0 if the vehicle has low performance. The variable\n",
    "    \"hiperf\" is 1 for high performance and 0 for medium or low performance.\n",
    "    So, a vehicle with high performance has a 1 for both of these variables.\n",
    "    The estimated \"utility\" from each performance level is therefore 0 for\n",
    "    low performance, 0.3841 for medium performance, and 0.3841+0.1099=0.4940\n",
    "    for high performance. Or, stated incrementally, the estimates imply that\n",
    "    going from low to medium performance increases \"utility\" by 0.3841, while\n",
    "    going from medium to high performance increases utility by 0.1099. These\n",
    "    estimates imply diminishing marginal utility of performance. \n",
    "  - There are three engine types, with alternative specific constants entered\n",
    "    for two of them (with the gas engine normalized to zero.) What do the\n",
    "    estimated constants imply about consumers' preferences for electric and\n",
    "    hybrid vehicles relative to gas? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = lx.Model(data)\n",
    "simple.utility_ca = (\n",
    "    PX(\"price_scaled\")\n",
    "    + PX(\"opcost_scaled\")\n",
    "    + PX(\"max_range\")\n",
    "    + PX(\"ev\")\n",
    "    + PX(\"hybrid\")\n",
    "    + PX(\"hiperf\")\n",
    "    + PX(\"medhiperf\")\n",
    ")\n",
    "simple.choice_ca_var = \"chosen\"\n",
    "simple.maximize_loglike(stderr=True, options={\"ftol\": 1e-9})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data Scaling\n",
    "\n",
    "Operating cost is scaled to be in tens of dollars, and price in tens of thousands. \n",
    "The optimizer operates most effectively when the diagonal of the hessian has about the \n",
    "same order of magnitude for all parameters, which can usually be accomplished by scaling \n",
    "variables such that their coefficients are about the same order of magnitude. To see the  \n",
    "effect of scaling, remove the scaling of operating cost, such that operating cost enters \n",
    "as dollars rather than tens of dollars. How many more iterations does the optimizer \n",
    "take to converge when operating cost is in dollars compared to when operating cost \n",
    "is in tens of dollars? For standard logit, the difference is run time is immaterial, \n",
    "since estimation is so quick in any case. But when running mixed logit and other \n",
    "models that require simulation, the difference can be considerable. It is always \n",
    "helpful, therefore, to run standard logit models to get the scaling right, since \n",
    "checking various scales is quick in standard logit, and then to use that scaling \n",
    "when you turn to mixed logit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## A First Mixed Logit Model\n",
    "\n",
    "Now estimate a mixed model with a fixed price coefficient and normal coefficients \n",
    "5. for all other attributes. This is probably the most common mixed logit specification. \n",
    "The code to do so is below.  It uses `lx.mixtures.Normal` to define Normal distributed\n",
    "parameter mixtures, with the first argument naming an existing parameter to mix, which \n",
    "will be the mean of the distribution, and the\n",
    "second giving a new parameter name that will be the (estimated) standard deviation of \n",
    "the mixture. Run this code and examine the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = simple.copy()\n",
    "for k in [\"opcost_scaled\", \"max_range\", \"ev\", \"hybrid\", \"hiperf\", \"medhiperf\"]:\n",
    "    mixed.mixtures.append(lx.mixtures.Normal(k, f\"s_{k}\"))\n",
    "mixed.n_draws = 200\n",
    "mixed.seed = 42\n",
    "mixed.maximize_loglike(stderr=True, options={\"ftol\": 1e-9})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "- Each random coefficient is distributed $N(B,W^2)$ where B and W are estimated.\n",
    "  Eg, the operating cost coefficient is estimated to have a mean of $-0.2149$\n",
    "  and standard deviation of $0.4668$, such that the variance is $0.4668^2=0.2179$.\n",
    "  Note, however, that the estimated $W$ can be negative, as occurs for some of\n",
    "  the coefficients. The negative sign in these cases is simply ignored, and\n",
    "  the standard deviation is the estimate without the negative sign. Here's\n",
    "  the reason: the parameter that is being estimated is not actually the standard\n",
    "  deviation; rather it is $W$ such that $W^2$ is the variance.  $W$ and $-W$\n",
    "  give the same variance, and hence are equivalent. Also, since the standard\n",
    "  deviation is defined as the square root of the variance, they give the same\n",
    "  standard deviation. The advantage of estimating $W$ instead of estimating a\n",
    "  standard deviation is that the optimization routine does not need to embody\n",
    "  constraints to keep the parameter positive. Another way to see the issue is\n",
    "  that a random variable that is $N(B,W^2)$ is created as $B+w*\\mu$ where $\\mu$\n",
    "  is standard normal, or equivalently as $B-W*\\mu$: both result in a term with\n",
    "  mean $B$ and standard deviation $W$. An implication of this parameterization\n",
    "  is that the starting values of $W$ should not be set at 0, but rather at some\n",
    "  value slightly away from zero. The reason is this: Since $W$ and $-W$ are\n",
    "  equivalent, the true log likelihood is symmetric around $W=0$ and hence is\n",
    "  flat at $W=0$. (The simulated log likelihood is not exactly symmetric due\n",
    "  to simulation noise.) If $W=0$ were used as the starting values, the gradient\n",
    "  would be zero and the optimization routine would have no guidance on the\n",
    "  direction to move. (If you want, you can change the starting value for $W$\n",
    "  to zero, and rerun the model. You'll see that it has a smaller improvement\n",
    "  in the first iteration and takes more iterations to converge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Considering Panel Data\n",
    "\n",
    "The mixed logit model above allows the preference parameters to vary across observations.\n",
    "But what we really want is preference parameters that vary across people.\n",
    "Remember, each person in this study was given 15 different questions to consider. \n",
    "To make preferences vary only by person, we add a `groupid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = mixed.copy()\n",
    "panel.groupid = \"person_id\"\n",
    "panel.maximize_loglike(stderr=True, options={\"ftol\": 1e-9})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "- Is this \"panel\" model better than the naive version?  Why do you think that is?\n",
    "\n",
    "- What is the estimated distribution of willingness to pay for a 1 dollar\n",
    "  reduction in operating cost? An advantage of having a fixed price coefficient\n",
    "  is that this distribution can be derived fairly easily. (If, in contrast,\n",
    "  the price coefficient is random, the willingness to pay is the ratio of two\n",
    "  random terms, which is more difficult to deal with.)\n",
    "\n",
    "- What share of the population is estimated to dislike reductions in operating\n",
    "  cost? To like high performance less than medium performance? Are these results\n",
    "  reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Simulation Noise\n",
    "\n",
    "Let's explore the effects of simulation noise. The seed is currently set at `42`\n",
    "(which is, of course, the [correct](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_(42)) \n",
    "value). Change the seed to other values to see the effect of different random \n",
    "draws on the estimation results. Try three or four seeds, to get a sense of \n",
    "how much change there is.  Also try changing the number of random draws. With\n",
    "more random draws, does the effect of differing random seeds change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Other Specifications\n",
    "\n",
    "Now let's return to specification issues. We have seen that the use of \n",
    "normal distributions creates unrealistic results for coefficients that \n",
    "should be the same sign for all people. Change the distributions for \n",
    "the operating cost, range, and the performance, to be `lx.mixtures.LogNormal` \n",
    "instead of Normal. Also, this is important: the lognormal distribution \n",
    "has support only on the positive side of zero. So, if you want to use \n",
    "a lognormal distribution for an undesirable attribute (for which all \n",
    "people have negative coefficients), then you need to use \n",
    "`lx.mixtures.NegLogNormal` instead.\n",
    "\n",
    "- Does this model fit the data better or worse than the model with\n",
    "  normal distributions, based on the log-likelihood value?\n",
    "\n",
    "- What are the estimated mean and standard deviation of the willingness\n",
    "  to pay for operating cost reductions? How do they compare to those\n",
    "  from the model with normal distributions?\n",
    "\n",
    "- Now allow the price coefficient to have a lognormal coefficient. What\n",
    "  is the estimated distribution for willingness to pay for operating cost\n",
    "  reductions?\n",
    "\n",
    "- Try other specification and find the model that you think is best. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
