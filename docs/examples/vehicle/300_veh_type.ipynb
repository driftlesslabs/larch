{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Vehicle Choice Mixed Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import larch as lx\n",
    "from larch import PX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "In this example, we will demonstrate the estimatation of parameters for\n",
    "mixed logit models.  The examples are based on a problem set originally published by Ken Train.\n",
    "\n",
    "To ensure good preformance and ease of use, estimating parameters for a mixed logit model in Larch requires the `jax` library as the compute engine.  Importing it here allows us to confirm that it is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax  # noqa: F401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The data represent consumers' choices among vehicles in stated preference experiments. The data are from a study that he did for Toyota and GM to assist them in their analysis of the potential marketability of electric and hybrid vehicles, back before hybrids were introduced.   \n",
    "\n",
    "In each choice experiment, the respondent was presented with three vehicles, with the price and other attributes of each vehicle described. The respondent was asked to state which of the three vehicles he/she would buy if the these vehicles were the only ones available in the market. There are 100 respondents in our dataset (which, to reduce estimation time, is a subset of the full dataset which contains 500 respondents.) Each respondent was presented with 15 choice experiments, and most respondents answered all 15. The attributes of the vehicles were varied over experiments, both for a given respondent and over respondents. The attributes are: price, operating cost in dollars per month, engine type (gas, electric, or hybrid), range if electric (in hundreds of miles between recharging), and the performance level of the vehicle (high, medium, or low). The performance level was described in terms of top speed and acceleration, and these descriptions did not vary for each level; for example, \"High\" performance was described as having a top speed of 100 mpg and 12 seconds to reach 60 mpg, and this description was the same for all \"high\" performance vehicles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    \"data.txt\",\n",
    "    names=[\n",
    "        \"person_id\",\n",
    "        \"case_id\",\n",
    "        \"chosen\",\n",
    "        \"price\",  # dollars\n",
    "        \"opcost\",  # dollars per month\n",
    "        \"max_range\",  # hundreds of miles (0 if not electric)\n",
    "        \"ev\",  # bool\n",
    "        \"gas\",  # bool\n",
    "        \"hybrid\",  # bool\n",
    "        \"hiperf\",  # High performance (bool)\n",
    "        \"medhiperf\",  # Medium or high performance (bool)\n",
    "    ],\n",
    "    sep=r\"\\s+\",\n",
    ")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Create `alt_id` values for each row within each group, and set\n",
    "the index on case and alternative id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"alt_id\"] = raw_data.groupby(\"case_id\").cumcount() + 1\n",
    "raw_data = raw_data.set_index([\"case_id\", \"alt_id\"])\n",
    "raw_data[\"price_scaled\"] = raw_data[\"price\"] / 10000\n",
    "raw_data[\"opcost_scaled\"] = raw_data[\"opcost\"] / 10\n",
    "data = lx.Dataset.construct.from_idca(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Simple MNL\n",
    "\n",
    "Start with a simple MNL model, using all the variable in the dataset without transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = lx.Model(data)\n",
    "simple.utility_ca = (\n",
    "    PX(\"price_scaled\")\n",
    "    + PX(\"opcost_scaled\")\n",
    "    + PX(\"max_range\")\n",
    "    + PX(\"ev\")\n",
    "    + PX(\"hybrid\")\n",
    "    + PX(\"hiperf\")\n",
    "    + PX(\"medhiperf\")\n",
    ")\n",
    "simple.choice_ca_var = \"chosen\"\n",
    "simple.maximize_loglike(stderr=True, options={\"ftol\": 1e-9});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "from pytest import approx\n",
    "\n",
    "assert simple.most_recent_estimation_result[\"loglike\"] == approx(-1399.1932)\n",
    "\n",
    "expected_value = {\n",
    "    \"price_scaled\": -0.4167,\n",
    "    \"opcost_scaled\": -0.1288,\n",
    "    \"max_range\": 0.4770,\n",
    "    \"ev\": -1.3924,\n",
    "    \"hybrid\": 0.3555,\n",
    "    \"hiperf\": 0.1099,\n",
    "    \"medhiperf\": 0.3841,\n",
    "}\n",
    "assert simple.parameters[\"value\"].to_series().to_dict() == approx(\n",
    "    expected_value, rel=5e-2\n",
    ")\n",
    "\n",
    "expected_stderr = {\n",
    "    \"price_scaled\": 0.0332,\n",
    "    \"opcost_scaled\": 0.0353,\n",
    "    \"max_range\": 0.1765,\n",
    "    \"ev\": 0.2766,\n",
    "    \"hybrid\": 0.1218,\n",
    "    \"hiperf\": 0.0838,\n",
    "    \"medhiperf\": 0.0855,\n",
    "}\n",
    "assert simple.parameters[\"std_err\"].to_series().to_dict() == approx(\n",
    "    expected_stderr, rel=2e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Mixture Model\n",
    "\n",
    "To create a mixed logit model, we can start with a copy of the simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = simple.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We assign mixtures to various parameters by providing a list of `Mixture` definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed.mixtures = [\n",
    "    lx.mixtures.Normal(k, f\"s_{k}\")\n",
    "    for k in [\"opcost_scaled\", \"max_range\", \"ev\", \"hybrid\", \"hiperf\", \"medhiperf\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The estimation of the mixed logit parameters sometimes performs\n",
    "poorly (i.e. may prematurely call itself converged) if you start\n",
    "from the MNL solution, so it can be advantageous to start from \n",
    "the null parameters instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed.pvals = \"null\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "There are several extra settings that can be manipulated on the\n",
    "mixed logit model, including the number of draws and a random seed\n",
    "for generating draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed.n_draws = 200\n",
    "mixed.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed.maximize_loglike(stderr=True, options={\"ftol\": 1e-9});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert mixed.most_recent_estimation_result[\"loglike\"] == approx(-1385.494141)\n",
    "\n",
    "expected_value = {\n",
    "    \"ev\": -3.032238243376885,\n",
    "    \"hiperf\": 0.1763708168391289,\n",
    "    \"hybrid\": 0.5461971243787561,\n",
    "    \"max_range\": 0.8886978044065789,\n",
    "    \"medhiperf\": 0.7325188113437849,\n",
    "    \"opcost_scaled\": -0.2198851109606838,\n",
    "    \"price_scaled\": -0.6478517959040359,\n",
    "    \"s_ev\": -2.804510536354318,\n",
    "    \"s_hiperf\": -0.5218085534690989,\n",
    "    \"s_hybrid\": 1.1432535820795153,\n",
    "    \"s_max_range\": -0.13064214289199153,\n",
    "    \"s_medhiperf\": 1.5746533061378736,\n",
    "    \"s_opcost_scaled\": 0.5204752418536094,\n",
    "}\n",
    "\n",
    "assert mixed.parameters[\"value\"].to_series().to_dict() == approx(\n",
    "    expected_value, rel=5e-2\n",
    ")\n",
    "\n",
    "expected_stderr = {\n",
    "    \"ev\": 0.7801142930984497,\n",
    "    \"hiperf\": 0.12483992427587509,\n",
    "    \"hybrid\": 0.19360417127609253,\n",
    "    \"max_range\": 0.32432201504707336,\n",
    "    \"medhiperf\": 0.2088639885187149,\n",
    "    \"opcost_scaled\": 0.07158942520618439,\n",
    "    \"price_scaled\": 0.10207334160804749,\n",
    "    \"s_ev\": 0.7572864890098572,\n",
    "    \"s_hiperf\": 0.8733952045440674,\n",
    "    \"s_hybrid\": 0.6600803732872009,\n",
    "    \"s_max_range\": 0.9942808151245117,\n",
    "    \"s_medhiperf\": 0.6126551628112793,\n",
    "    \"s_opcost_scaled\": 0.18554426729679108,\n",
    "}\n",
    "assert mixed.parameters[\"std_err\"].to_series().to_dict() == approx(\n",
    "    expected_stderr, rel=5e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Panel Data\n",
    "\n",
    "In the mixed logit model above, we have ignored the fact that \n",
    "we have \"panel data\", where multiple observations are made by the\n",
    "same decision maker who (presumably) has stable preferences with\n",
    "respect to the choice attributes.  We can tell Larch which data\n",
    "column represents the panel identifiers in the `groupid` attribute,\n",
    "(which we set to `\"person_id\"`) and then\n",
    "use that information to build a significantly better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = mixed.copy()\n",
    "panel.groupid = \"person_id\"\n",
    "panel.maximize_loglike(stderr=True, options={\"ftol\": 1e-9});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert panel.most_recent_estimation_result[\"loglike\"] == approx(-1330.442871)\n",
    "\n",
    "expected_value = {\n",
    "    \"ev\": -1.7034994106596084,\n",
    "    \"hiperf\": 0.09213393502033553,\n",
    "    \"hybrid\": 0.46842352186376457,\n",
    "    \"max_range\": 0.4627547334553541,\n",
    "    \"medhiperf\": 0.5090292596924697,\n",
    "    \"opcost_scaled\": -0.1388731660486894,\n",
    "    \"price_scaled\": -0.5014897667296647,\n",
    "    \"s_ev\": -0.921130570903971,\n",
    "    \"s_hiperf\": -0.4193628031632754,\n",
    "    \"s_hybrid\": 0.8446756225312494,\n",
    "    \"s_max_range\": 0.7102007254766374,\n",
    "    \"s_medhiperf\": 0.6029327016972847,\n",
    "    \"s_opcost_scaled\": -0.3470455945572811,\n",
    "}\n",
    "assert panel.parameters[\"value\"].to_series().to_dict() == approx(\n",
    "    expected_value, rel=5e-2\n",
    ")\n",
    "\n",
    "expected_stderr = {\n",
    "    \"ev\": 0.3431136906147003,\n",
    "    \"hiperf\": 0.10426269471645355,\n",
    "    \"hybrid\": 0.16409245133399963,\n",
    "    \"max_range\": 0.22775666415691376,\n",
    "    \"medhiperf\": 0.11354632675647736,\n",
    "    \"opcost_scaled\": 0.052873723208904266,\n",
    "    \"price_scaled\": 0.039680227637290955,\n",
    "    \"s_ev\": 0.22132474184036255,\n",
    "    \"s_hiperf\": 0.14358796179294586,\n",
    "    \"s_hybrid\": 0.133216992020607,\n",
    "    \"s_max_range\": 0.18694375455379486,\n",
    "    \"s_medhiperf\": 0.14173047244548798,\n",
    "    \"s_opcost_scaled\": 0.04932473972439766,\n",
    "}\n",
    "assert panel.parameters[\"std_err\"].to_series().to_dict() == approx(\n",
    "    expected_stderr, rel=5e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We can review summary statistics about the distibution of the mixed parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.mixture_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert panel.mixture_summary()[\"mean\"].to_dict() == approx(\n",
    "    {\n",
    "        \"ev\": -1.703514575958252,\n",
    "        \"hiperf\": 0.09218784421682358,\n",
    "        \"hybrid\": 0.46854260563850403,\n",
    "        \"max_range\": 0.4628429114818573,\n",
    "        \"medhiperf\": 0.5090671181678772,\n",
    "        \"opcost_scaled\": -0.13884519040584564,\n",
    "    },\n",
    "    rel=1e-2,\n",
    ")\n",
    "assert panel.mixture_summary()[\"share +\"].to_dict() == approx(\n",
    "    {\n",
    "        \"ev\": 0.032249998301267624,\n",
    "        \"hiperf\": 0.5868499875068665,\n",
    "        \"hybrid\": 0.7102000117301941,\n",
    "        \"max_range\": 0.7425000071525574,\n",
    "        \"medhiperf\": 0.800599992275238,\n",
    "        \"opcost_scaled\": 0.3444499969482422,\n",
    "    },\n",
    "    rel=1e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "The \"share\" columns show the share of random simulations with positive, negative, or \n",
    "zero values for each model parameter. This summary shows that about a third of people \n",
    "show a positive parameter on operating costs, i.e. they prefer higher costs.  That's \n",
    "probably not reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Log-Normal Parameter\n",
    "\n",
    "Let's change the operating cost parameter to have a negative log-normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2 = panel.copy()\n",
    "panel2.mixtures[0] = lx.mixtures.NegLogNormal(\"opcost_scaled\", \"s_opcost_scaled\")\n",
    "panel2.pvals = \"null\"\n",
    "panel2.maximize_loglike(stderr=True, options={\"ftol\": 1e-9});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2.mixture_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2.mixture_density(\"opcost_scaled\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel2.mixture_density(\"hybrid\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
