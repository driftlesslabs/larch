{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 12: Vehicles per Adult\n",
    "\n",
    "Model 12 considers the number of autos divided by the number of persons of driving age in the household. (pp. 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import larch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "larch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "This example is a mode choice model built using the MTC example dataset. First we create the DB and Model objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = larch.examples.MTC(format=\"dataset\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = larch.Model(d, compute_engine=\"numba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Then we can build up the utility function. We’ll use some :ref:idco data first, using the Model.utility.co attribute. This attribute is a dict-like object, to which we can assign :class:LinearFunction objects for each alternative code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from larch import PX, P, X\n",
    "\n",
    "for a in [2, 3]:\n",
    "    m.utility_co[a] = +P(\"hhinc#2,3\") * X(\"hhinc\")\n",
    "for a in [4, 5, 6]:\n",
    "    m.utility_co[a] = +P(f\"hhinc#{a}\") * X(\"hhinc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Sometimes we may want to define a part of the utility function that is common across all (or almost all) of the alternatives. We can access a dictionary (more generically called a “mapping”) of alternative codes to alternative names, which can be found via the Dataset.dc.alts_mapping attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.dc.alts_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Using this like a standard Python dictionary, we can iterate over all the alternatives, skipping 1, and setting alternative specific constants (ASC’s) for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, name in d.dc.alts_mapping.items():\n",
    "    if a == 1:\n",
    "        continue\n",
    "    m.utility_co[a] += P(\"ASC_\" + name) + P(\"vehbyadlt_\" + name) * X(\"numveh/numadlt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Next we’ll use some idca data, with the utility_ca attribute. This attribute is only a single :class:LinearFunction that is applied across all alternatives using :ref:idca data. Because the data is structured to vary across alternatives, the parameters (and thus the structure of the :class:LinearFunction) does not need to vary across alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.utility_ca = (\n",
    "    +PX(\"totcost\")\n",
    "    + P(\"motorized_time\") * X(\"(altid <= 4) * tottime\")\n",
    "    + P(\"nonmotorized_time\") * X(\"(altid > 4) * tottime\")\n",
    "    + P(\"motorized_ovtbydist\") * X(\"(altid <= 4) * ovtt/dist\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Lastly, we need to identify idca Format data that gives the availability for each alternative, as well as the number of times each alternative is chosen. (In traditional discrete choice analysis, this is often 0 or 1, but it need not be binary, or even integral.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.availability_ca_var = \"avail\"\n",
    "m.choice_ca_var = \"chose\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "And let’s give our model a descriptive title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.title = \"MTC Example 12, Autos per Adult\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We can view a summary of the choices and alternative availabilities to make sure the model is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.choice_avail_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We’ll set a parameter cap (bound) at +/- 20, which helps improve the numerical stability of the optimization algorithm used in estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_cap(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Having created this model, we can then estimate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert m.compute_engine == \"numba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = m.maximize_loglike(stderr=True, method=\"bhhh\")\n",
    "m.calculate_parameter_covariance()\n",
    "m.loglike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.parameter_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "It is a little tough to read this report because the parameters show up in alphabetical order. We can use the reorder method to fix this and group them systematically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.ordering = (\n",
    "    (\n",
    "        \"LOS\",\n",
    "        \".*cost.*\",\n",
    "        \".*time.*\",\n",
    "        \".*dist.*\",\n",
    "    ),\n",
    "    (\n",
    "        \"Income\",\n",
    "        \"hhinc.*\",\n",
    "    ),\n",
    "    (\"Ownership\", \"vehbyadlt.*\"),\n",
    "    (\n",
    "        \"ASCs\",\n",
    "        \"ASC.*\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.parameter_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Finally, let's print model statistics.  Note that if you want LL at constants you need to run a separate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.estimation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "from pytest import approx\n",
    "\n",
    "revealed_x = dict(zip(m.pnames, result.x))\n",
    "assert result[\"loglike\"] == approx(-3490.3579715315, rel=1e-5), result[\"loglike\"]\n",
    "\n",
    "expected_x = {\n",
    "    \"ASC_Bike\": -1.9627758221667733,\n",
    "    \"ASC_SR2\": -1.536865403172976,\n",
    "    \"ASC_SR3+\": -3.0235322387181176,\n",
    "    \"ASC_Transit\": 1.0496197735578745,\n",
    "    \"ASC_Walk\": -0.21728572066754234,\n",
    "    \"hhinc#2,3\": -0.0013240180758255255,\n",
    "    \"hhinc#4\": -0.004616956633813837,\n",
    "    \"hhinc#5\": -0.011663606663415026,\n",
    "    \"hhinc#6\": -0.00764683683920611,\n",
    "    \"motorized_ovtbydist\": -0.18489944106276082,\n",
    "    \"motorized_time\": -0.03803405138642473,\n",
    "    \"nonmotorized_time\": -0.046633097590087214,\n",
    "    \"totcost\": -0.004179712660535923,\n",
    "    \"vehbyadlt_Bike\": -0.6418346308251331,\n",
    "    \"vehbyadlt_SR2\": -0.594456791391658,\n",
    "    \"vehbyadlt_SR3+\": -0.447408231859455,\n",
    "    \"vehbyadlt_Transit\": -1.4092358161539453,\n",
    "    \"vehbyadlt_Walk\": -0.7935735138713005,\n",
    "}\n",
    "for k in expected_x:\n",
    "    assert revealed_x[k] == approx(expected_x[k], 0.03), (\n",
    "        f\"{k}, {revealed_x[k] / expected_x[k]}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
