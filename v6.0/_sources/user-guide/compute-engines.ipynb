{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Compute Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import larch as lx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Larch provides a Python interface for setting up, estimating, and applying\n",
    "discrete choice models.  Under the hood, Larch runs on a \"compute engine\",\n",
    "which provides all the back-end code needed to execute the mathematical \n",
    "computations that power the models.\n",
    "\n",
    "## Available Engines\n",
    "\n",
    "Larch currently offers two compute engines: `numba` and `jax`.  \n",
    "\n",
    "The `numba` compute engine is relatively fast, and is the best choice for \n",
    "estimating basic models, such as simple multinomial logit (MNL) and nested \n",
    "logit (NL) models, especially with small to moderate sized datasets.  It\n",
    "employs \"jit\" compiled functions that run faster than regular Python, which \n",
    "are optimized for the model type but not specifically for each dataset.\n",
    "The numba engine is *not* available for mixed logit models.\n",
    "\n",
    "The `jax` compute engine runs quite fast and efficiently, and is the best \n",
    "choice for estimating complicated models, especially mixed logit models.\n",
    "When using this engine, each model step is compiled and optimized\n",
    "specifically for the data and structures used in that model.  Compiled code \n",
    "is *not* cached to disk, so this optimization adds a significant amount of \n",
    "\"fixed\" overhead time for model estimation and application.  However, for \n",
    "large and complex models this overhead can be well worth the investment.\n",
    "\n",
    "## Setting Engines\n",
    "\n",
    "The compute engine can be chosen by providing a `compute_engine` argument\n",
    "at model initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lx.Model(compute_engine=\"jax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Alternatively, the engine can be selected by changing the `compute_engine` \n",
    "attribute later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compute_engine = \"numba\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "If you try to use an engine type that is not available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "m.compute_engine = \"steam\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
