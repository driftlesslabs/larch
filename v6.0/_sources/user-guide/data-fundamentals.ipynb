{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "(data-fundamentals)=\n",
    "# Data for Discrete Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import larch as lx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This discussion of data for discrete choice modeling is broken into two parts.  The first part \n",
    "is a review of the abstract fundamentals, and is recommended for users new to discrete choice modeling.\n",
    "\n",
    "If you are are already familar with the various kinds of discrete choice data (case-only and case-alt, \n",
    "or wide and tall), you probably want to skip the the second section which focuses on the \n",
    "[practical implementation](Practical-Data-Formating-in-Larch) of these formats when used in Larch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Fundamental Data Formats\n",
    "\n",
    "When working with discrete choice models in Larch, we will generally\n",
    "receive data to input into the system in one of two basic formats: the case-only (\"idco\")\n",
    "format or the case-alternative (\"idca\") format. \n",
    "\n",
    "This are sometimes referred to as\n",
    "IDCase (each record contains all the information for mode choice over\n",
    "alternatives for a single trip) or IDCase-IDAlt (each record contains all the\n",
    "information for a single alternative available to each decision maker so there is one\n",
    "record for each alternative for each choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "(idco)=\n",
    "### idco Format\n",
    "\n",
    "In the **idco** case-only format, each record provides all the relevant information\n",
    "about an individual choice, including the variables related to the decision maker\n",
    "or the choice itself, as well as alternative-related variables for all available\n",
    "alternatives, and a variable indicating which alternative was chosen. This style \n",
    "of data has a variety of names in the choice modeling literature, including\n",
    "\"IDCase\", \"case-only\", and \"wide\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_co = pd.read_csv(\"example-data/tiny_idco.csv\", index_col=\"caseid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "data_co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "(idca)=\n",
    "### idca Format\n",
    "\n",
    "In the [idca](idca) case-alternative format, each record can include information on the variables\n",
    "related to the decision maker or the choice itself, the attributes of that\n",
    "particular alternative, and a choice variable that indicates whether the\n",
    "alternative was or was not chosen. This style of data has a variety of names in the \n",
    "choice modeling literature, including \"IDCase-IDAlt\", \"case-alternative\", and \"tall\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ca = pd.read_csv(\"example-data/tiny_idca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "data_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "(idce)=\n",
    "#### sparse vs dense\n",
    "\n",
    "The `idca` format actually has two technical variations, a sparse version and a \n",
    "dense version. The table shown above is a sparse version, where any alterative that \n",
    "is not available is simply missing from the data table.  Thus, in caseid 2 above, \n",
    "there are only 2 rows, not 3.  By dropping these rows, this data storage is potentially\n",
    "more efficient than the dense version.  But, in cases where the number of missing alternatives\n",
    "is managably small (less than half of all the data, certainly) it can be much more computationally\n",
    "efficient to simply store and work with the dense array. \n",
    "\n",
    "In *Larch*, these two distinct sub-types of idca data are labeled so \n",
    "that the dense version labeled as `idca` and the sparse version \n",
    "labeled as `idce`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Data Conversion\n",
    "\n",
    "Converting between `idca` format data and `idco` format in Python can be super easy if the alternative\n",
    "id's are stored appropriately in a two-level MultiIndex. In that case, we can simply `stack` or `unstack` the DataFrame, and change formats.  This is typically more readily available when switching from `idca` to `idco`\n",
    "formats, as the alterative id's typically appear in a column of the DataFrame that can be used for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ca.set_index([\"caseid\", \"altid\"]).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Getting our original `idco` data into `idca` format is not so clean, as there's no analagous\n",
    "`set_columns` method in pandas, and even if there were, the alternative codes are not typically\n",
    "neatly arranged in a row of data. We can force it to work, but it's not pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_ca = data_co.T.set_index(\n",
    "    pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            [\"Car\", \"Income\"],\n",
    "            [\"Car\", \"Time\"],\n",
    "            [\"Car\", \"Cost\"],\n",
    "            [\"Bus\", \"Time\"],\n",
    "            [\"Bus\", \"Cost\"],\n",
    "            [\"Walk\", \"Time\"],\n",
    "            [\"Car\", \"Chosen\"],\n",
    "        ],\n",
    "        names=(\"alt\", \"var\"),\n",
    "    )\n",
    ").T.stack(0)\n",
    "forced_ca[[\"Chosen\", \"Income\"]] = (\n",
    "    forced_ca[[\"Chosen\", \"Income\"]]\n",
    "    .groupby(\"caseid\")\n",
    "    .transform(lambda x: x.fillna(x.value_counts().index[0]))\n",
    ")\n",
    "forced_ca[\"Chosen\"] = (\n",
    "    forced_ca[\"Chosen\"] == forced_ca.index.get_level_values(\"alt\")\n",
    ").astype(float)\n",
    "forced_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Practical Data Formating in Larch\n",
    "\n",
    "The data formats described above are relevant when storing data in \n",
    "a tabular (two-dimensional) format.  This is quite common and generally\n",
    "expected, especially for data exchange between most software tools,\n",
    "but Larch doesn't require you to choose one or the other.\n",
    "\n",
    "Instead, Larch uses a [`Dataset`](larch.dataset.Dataset) structure based\n",
    "on `xarray`, to store and use a collection of relevant variables, and \n",
    "each variable can be stored in either [idco](idco) or [idca](idca) format, as \n",
    "appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lx.dataset.merge(\n",
    "    [\n",
    "        data_co[[\"Income\", \"Chosen\"]].to_xarray(),\n",
    "        data_ca.set_index([\"caseid\", \"altid\"])[[\"Time\", \"Cost\"]].to_xarray(),\n",
    "    ],\n",
    "    caseid=\"caseid\",\n",
    "    alts=\"altid\",\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "As we saw above, it's quite easy to move from [idca](idca) to [idco](idco) format,\n",
    "and Larch can apply those transformations automatically when loading [idca](idca)\n",
    "data, using the [`Dataset.construct.from_idca`](`Dataset.construct.from_idca`) method.  \n",
    "In the example below, note that the `Income` variable has automatically\n",
    "been collapsed to [idco](idco), while the other variables remain as [idca](idca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lx.Dataset.construct.from_idca(\n",
    "    data_ca.set_index([\"caseid\", \"altid\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "from pytest import approx\n",
    "\n",
    "t = lx.Dataset.construct.from_idca(\n",
    "    data_ca.set_index([\"caseid\", \"altid\"]),\n",
    ")\n",
    "\n",
    "assert all(t.altid == [1, 2, 3])\n",
    "assert all(t.alt_names == [\"Bus\", \"Car\", \"Walk\"])\n",
    "assert t.Cost.where(t._avail_, 0).data == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [100, 150, 0],\n",
    "            [100, 125, 0],\n",
    "            [75, 125, 0],\n",
    "            [150, 225, 0],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "assert t.Time.where(t._avail_, 0).data == approx(\n",
    "    np.array(\n",
    "        [\n",
    "            [40, 30, 20],\n",
    "            [35, 25, 0],\n",
    "            [50, 40, 30],\n",
    "            [20, 15, 10],\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Loading data in sparse format is as easy as swapping out \n",
    "[`from_idca`](larch.Dataset.from_idca) for \n",
    "[`from_idce`](larch.Dataset.from_idce).  The resulting\n",
    "dataset will have a similar collection of variables, but \n",
    "each idca variable is stored in a one-dimensional array,\n",
    "using a variety of the compressed sparse row data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lx.Dataset.construct.from_idce(\n",
    "    data_ca.set_index([\"caseid\", \"altid\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "z = lx.Dataset.construct.from_idce(\n",
    "    data_ca.set_index([\"caseid\", \"altid\"]),\n",
    ")\n",
    "assert z.Income.dims == (\"caseid\",)\n",
    "assert z.Time.dims == (\"_casealt_\",)\n",
    "assert z[\"_caseptr_\"].shape == (5,)\n",
    "assert all(z[\"_caseptr_\"] == [0, 3, 5, 8, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "For the most part, data used in the utility functions of discrete choice models enters into the utility function as part of a linear-in-parameters function.  That is, we have some \"data\" that expresses an attribute of some part of the transportation system as a number, we multiply that by some numerical parameter that will be estimated, and we sum up the total over all the data-times-parameter operations.  This kind of structure is known as \"linear algebra\" and it's something computers can do super fast, as long as all the data and all the parameters are queued up in memory in the right formats.  So, typically it is optimal to pre-compute the \"data\" part of the process into one large contiguous array of floating point values, regardless if the values otherwise seem to be binary or integers. Most tools, such as Larch, will do much of this work for you, so you don't need to worry about it too much.   \n",
    "\n",
    "There are two notable exceptions to this guideline: \n",
    "\n",
    "- *choices*: the data that represents the observed choices, which are inherently categorical\n",
    "- *availability*: data that represents the availability of each choice, which is inherently boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "When we are looking at discrete choices, it is natural to employ a categorical data type for at least the \"choice\" data itself, if not for other columns as well.  Pandas can convert columns to categorical data simply by assigning the type \"category\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = data_co[\"Chosen\"].astype(\"category\")\n",
    "choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Once we have categorical data, if we like we can work with the underlying code values instead of the original raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The `cat.categories` attribute contains the array of values matching each of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "When using `astype(\"category\")` there's no control over the ordering of the categories.  If we want\n",
    "to control the apparent order (e.g. we already have codes defined elsewhere such that Car is 1, Bus is 2, and walk is 3) then we can explicitly set the category value positions using `pd.CategoricalDtype` instead of `\"category\"`.\n",
    "Note that the `cat.codes` numbers used internally by categoricals start with zero as standard in Python,\n",
    "so if you want codes to start with 1 you need to include a dummy placeholder for zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices1 = data_co[\"Chosen\"].astype(pd.CategoricalDtype([\"_\", \"Car\", \"Bus\", \"Walk\"]))\n",
    "choices1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices1.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "To be clear, by asserting the *placement* ordering of alternative like this, we are not simultaneously asserting that the alternatives are ordinal.  Put another way, we are forcing Car to be coded as 1 and Bus to be coded as 2, but we are not saying that Car is less than Bus.  Pandas categoricals can allow this, by adding `ordered=True` to the CategoricalDtype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.CategoricalDtype([\"NoCars\", \"1Car\", \"2Cars\", \"3+Cars\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "One-hot encoding, also known as dummy variables, is the creation of a seperate binary-valued column for every categorical value.  We can convert a categorical data column into a set of one-hot encoded columns using the `get_dummies` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "It's not required to have first converted the data to a categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data_co[\"Chosen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Encoding with `xarray`\n",
    "\n",
    "The `xarray` library doesn't use formal \"categorical\" datatypes, but we can still use\n",
    "the `get_dummies` function to explode choice and availability data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Chosen_ca\"] = lx.DataArray(\n",
    "    pd.get_dummies(data_co[\"Chosen\"]).rename_axis(columns=\"altid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Working with Skims\n",
    "\n",
    "Sometimes, data used by Larch for estimating transportation choices is available as \"skims\".\n",
    "This data is usually stored in one of two formats: open matrix files, or indexed csv tables.\n",
    "Both formats are readily usable by models in Larch.  For open matrix files, there is the \n",
    "`OMX` class, which is derived from a PyTables File object and allows you to open and refer to\n",
    "open matrix files on disk.  When you first access an open matrix file, only the meta-data is\n",
    "actually read, allowing you to see what is in the file before actually loading the whole thing\n",
    "into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from larch.omx import OMX\n",
    "\n",
    "skims = OMX(lx.example_file(\"exampville_skims.omx\"), mode=\"r\")\n",
    "skims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "It is easy to convert an OMX object into a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skims_dataset = skims.to_dataset()\n",
    "skims_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "The other common (although less efficient) format for skim data is an indexed table.\n",
    "This could be a csv file, with \"X\" and \"Y\" coordinates given in a pair of columns, and\n",
    "one or more variables in other columns.  Data in this format might look something like \n",
    "this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skim_df = pd.read_csv(\"example-data/exampville_skims.csv\")\n",
    "skim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "As shown above, loading this format of data into a pandas DataFrame is as simple \n",
    "as reading the CSV file. in the usual way.  Converting it to an xarray Dataset is\n",
    "also easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_df.set_index([\"I\", \"J\"]).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "If you're going to be reading and writing the same datasets over and over, it \n",
    "can be advantageous to store them in a format that's more efficient for reading and \n",
    "writing, such as the ZARR format.  You can write a dataset to zarr using `Dataset.to_zarr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skims_dataset.to_zarr(\"example-data/example-skims.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Opening a dataset that has been saved in ZARR format is possible using the `open_zarr` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = xr.open_zarr(\"example-data/example-skims.zarr\")\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The `open_zarr` function returns promptly because, like the OMX class, \n",
    "by default it does not actually read the underlying data into memory, just the \n",
    "meta-data that identifies variable names, shapes, and types.  Actually loading the\n",
    "data itself can be deferred until it is actually needed, or it can be read eagerly\n",
    "using the `load` method.  You see below the *dask.array* data elements have been replaced\n",
    "with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z.load()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "299.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
