{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "Larch includes several tools to support analysis of estimated model results.  We will demonstrate\n",
    "some of these features here using the simple example model for MTC mode choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larch as lx\n",
    "\n",
    "m = lx.example(1)\n",
    "m.estimate(quiet=True)\n",
    "m.parameter_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice and Availability Summary\n",
    "\n",
    "A simple aggregate analysis of the data's choice and availablity statistics is available\n",
    "via `choice_avail_summary` even without any model structure or parameters, as this \n",
    "summary can be constructed from the data alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.choice_avail_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Predictions\n",
    "\n",
    "Larch includes methods to analyze model predictions across various dimensions.  The [`analyze_predictions_co`](larch.Model.analyze_predictions_co)\n",
    "method can be used to examine how well the model predicts choices against any available (or computable)\n",
    "attibute of the chooser.  For example, consider the basic example model for MTC mode choice.\n",
    "This model includes a utility function that incorporates alternative specific constants, level of\n",
    "service variables (time and cost), as well as alternative-specific parameters to account for income.\n",
    "\n",
    "We may be interested in knowing how well the model predicts choices across various age levels. To\n",
    "see this, we can pass the \"age\" variable to [`analyze_predictions_co`](larch.Model.analyze_predictions_co):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_predictions_co(\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a table of mode choices, segregated into five age categories. These \n",
    "categories were selected by the `pandas.qcut` functions to roughly divide the\n",
    "sample of observations into quintiles.  We can see the mean and standard deviation\n",
    "of the model predictions for each mode choice in each age group, as well as\n",
    "the actual observed count of choices in each group.  The `signif` column gives\n",
    "the level of significance of the difference between the predicted totals and\n",
    "the observed totals.  A small number in this column indicates that, assuming \n",
    "the model is correct, is would be very unlikely to actually collect the observed\n",
    "data.  We can see the very small significance values in the lowest age group\n",
    "are bold and highlighted in red, as these very small numbers are suggesting there\n",
    "is a problem in our model.\n",
    "\n",
    "We can also generate a figure to present this same information in a more\n",
    "visual representation, using [`analyze_predictions_co_figure`](larch.Model.analyze_predictions_co_figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_predictions_co_figure(\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer to analyze age using specific categorical breakpoints, we can do so\n",
    "by providing the preferred explicit bin breakpoints to the \n",
    "[`analyze_predictions_co`](larch.Model.analyze_predictions_co) method, which\n",
    "are then used by [`pandas.cut`](pandas.cut) to categorize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_predictions_co(\"age\", bins=[0, 25, 45, 65, 99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply non-uniform weights to the observations, by passing an expression to the `wgt` argument of \n",
    "the [`analyze_predictions_co`](larch.Model.analyze_predictions_co) method.  For example, here we \n",
    "overweight persons who work in the core CBD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_predictions_co(\"age\", wgt=\"1.5 if wkccbd else 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that weights are *not* normalized within the analysis, so if you use something \n",
    "like a population expansion weight or other large value, you will see results that\n",
    "appear to be extraordinarily significant across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_predictions_co(\"age\", wgt=\"1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To counteract this effect, you can normalize weights before providing the data to Larch, \n",
    "or explicitly in the `wgt` expression.\n",
    "\n",
    "Weights in [`analyze_predictions_co`](larch.Model.analyze_predictions_co) are computed \n",
    "seperately from weighting that is applied in estimation, but if weights are used in\n",
    "estimation you can choose to apply the same weights here by setting `wgt=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticity\n",
    "\n",
    "Users can also review the elasticity of demand with respect to various input variables, using the \n",
    "[`analyze_elasticity`](larch.Model.analyze_elasticity) method.  This method accepts a variable\n",
    "name and it computes the elasticity with respect to that variable.  For `idca` format variables, \n",
    "you can also provide an `altid` (the integer code for an individual alternative), and the \n",
    "elasticity will be computed with respect to a change in only that alterantives values for the \n",
    "selected variable.  For example, in the model we are reviewing here, cost is stored in a single\n",
    "`idca` format variable, but if we want to see the elasticity with respect to transit cost specifically\n",
    "we can do so like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_elasticity(\"totcost\", altid=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `idco` format variables, we can still compute elasticities, but only without the `altid` argument,\n",
    "as it does not make sense to try to have an elasticity with respect to something like \"income when \n",
    "choosing to drive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_elasticity(\"hhinc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticities can also be computed by segments of choosers, in a manner mirroring the segmentation available\n",
    "from the [`analyze_predictions_co`](larch.Model.analyze_predictions_co) method.  By adding the `q` argument\n",
    "to break the data into quantiles, (and optionally the `n` to set the number of quantiles), we can see elasticity\n",
    "by various segments.  For example, here we can see the price elasticity of demand for transit is (slightly)\n",
    "increasing as income increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.analyze_elasticity(\"totcost\", altid=4, q=\"hhinc\", n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Probability Array\n",
    "\n",
    "In addition to the pre-packaged analysis above, Larch makes available the full \n",
    "[`probability`](larch.Model.probability) array (among other internals), so that \n",
    "advanced users can slice and analyze the results in arbitrarily complex ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.probability(return_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conjunction with manipulations of the data and model parameters, users can evaluate nearly any type of elasticity,\n",
    "reponse function, or summary statistic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
